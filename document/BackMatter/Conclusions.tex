\begin{conclusions}
    \label{sec:19}
        
            La arquitectura propuesta más que un algortimo optimizador es un marco de trabajo que generaliza el concepto de perceptron, puesto que en lugar de estimar 
            hiper parámetros muy complicados de hallar, se ofrece una alternativa para minimizar el esfuerzo que representa tan ardua tarea desde el número de neuronas y 
            capas ocultas hasta la función de activación, además de ser altamente paralelizable, lo cual es un estándar entre los algoritmos de aprendizaje de máquinas de 
            hoy en día. \\
            \begin{enumerate}
                \item Podemos concluir que el algoritmo propuesto es convergente condicionalmente, y tal condición la da el agente coordinado. 
                \item Se ha explorado el enfoque de intervalos para representar incertidumbre.
                \item Se han definido las restricciones del lenguaje necesarios para que los agentes se comunique entre sí y minimicen la función objetivo.
                \item Se implementó un prototipo básico de uso.
            \end{enumerate}
\end{conclusions}
